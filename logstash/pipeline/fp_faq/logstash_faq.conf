input {
	file {
		path => "/usr/share/logstash/pipeline/fp_faq/トークCARE_想定問答集.csv"
		start_position => "beginning"
		sincedb_path => "/dev/null"
		codec => multiline {
            pattern => "^,"
			# negate => "true"
            what => "previous"
			auto_flush_interval => 1        
        }
  }
}
filter {
	csv {
		separator => ","
		columns => ["topic","question","answer","evidence"]
	}
	mutate {
		gsub => ["message", "\r\n,", ""]
		remove_field => ["path", "host","@timestamp","@version","answer","evidence"]
	}
	grok {
		# break_on_match => "false"
		match => [
			"message", "\"%{DATA:answers}\",%{DATA:evidences},\"%{DATA:answers}\",%{DATA:evidences},\"%{DATA:answers}\",%{DATA:evidences},\"%{DATA:answers}\",%{DATA:evidences},\"%{DATA:answers}\",%{DATA:evidences},\"%{DATA:answers}\",%{DATA:evidences},\"%{DATA:answers}\",%{DATA:evidences},\"%{DATA:answers}\",%{DATA:evidences},\"%{DATA:answers}\",%{DATA:evidences},\"%{DATA:answers}\",%{GREEDYDATA:evidences}",
			"message", "\"%{DATA:answers}\",%{DATA:evidences},\"%{DATA:answers}\",%{DATA:evidences},\"%{DATA:answers}\",%{DATA:evidences},\"%{DATA:answers}\",%{DATA:evidences},\"%{DATA:answers}\",%{DATA:evidences},\"%{DATA:answers}\",%{DATA:evidences},\"%{DATA:answers}\",%{DATA:evidences},\"%{DATA:answers}\",%{DATA:evidences},\"%{DATA:answers}\",%{GREEDYDATA:evidences}",
			"message", "\"%{DATA:answers}\",%{DATA:evidences},\"%{DATA:answers}\",%{DATA:evidences},\"%{DATA:answers}\",%{DATA:evidences},\"%{DATA:answers}\",%{DATA:evidences},\"%{DATA:answers}\",%{DATA:evidences},\"%{DATA:answers}\",%{DATA:evidences},\"%{DATA:answers}\",%{DATA:evidences},\"%{DATA:answers}\",%{GREEDYDATA:evidences}",
			"message", "\"%{DATA:answers}\",%{DATA:evidences},\"%{DATA:answers}\",%{DATA:evidences},\"%{DATA:answers}\",%{DATA:evidences},\"%{DATA:answers}\",%{DATA:evidences},\"%{DATA:answers}\",%{DATA:evidences},\"%{DATA:answers}\",%{DATA:evidences},\"%{DATA:answers}\",%{GREEDYDATA:evidences}",
			"message", "\"%{DATA:answers}\",%{DATA:evidences},\"%{DATA:answers}\",%{DATA:evidences},\"%{DATA:answers}\",%{DATA:evidences},\"%{DATA:answers}\",%{DATA:evidences},\"%{DATA:answers}\",%{DATA:evidences},\"%{DATA:answers}\",%{GREEDYDATA:evidences}",
			"message", "\"%{DATA:answers}\",%{DATA:evidences},\"%{DATA:answers}\",%{DATA:evidences},\"%{DATA:answers}\",%{DATA:evidences},\"%{DATA:answers}\",%{DATA:evidences},\"%{DATA:answers}\",%{GREEDYDATA:evidences}",
			"message", "\"%{DATA:answers}\",%{DATA:evidences},\"%{DATA:answers}\",%{DATA:evidences},\"%{DATA:answers}\",%{DATA:evidences},\"%{DATA:answers}\",%{GREEDYDATA:evidences}",
			"message", "\"%{DATA:answers}\",%{DATA:evidences},\"%{DATA:answers}\",%{DATA:evidences},\"%{DATA:answers}\",%{GREEDYDATA:evidences}",
			"message", "\"%{DATA:answers}\",%{DATA:evidences},\"%{DATA:answers}\",%{GREEDYDATA:evidences}",
			"message", "\"%{DATA:answers}\",%{GREEDYDATA:evidences}"
			]
		overwrite => ["message"]
		remove_field => ["message"]
	}
	# ruby {
    #     code =>'
    #     arr = event["message"].split(",\"")
	# 	arr.each_with_index do |item,index|
    #     	if index % (arr.length-1) = 0
	# 			event["answer"] = arr[0]
	# 			event["tag"] = arr[1]
	# 			event["types"] = arr[2]
	# 			event["uid"] = arr[3]
	# 			event["msg"] = arr[4]
    #     	elsif arr.length == 3
	# 			event["hostname"] = arr[0]
	# 			event["tag"] = arr[1]
	# 			event["msg"] = arr[2]
	# 		end
    #     end'
    #    remove_field => ['type','_id','input_type','tags','message','beat','offset']
	# }
}

## Add your filters / logstash plugins configuration here

output {
	elasticsearch {
		hosts => "elasticsearch:9200"
		user => "elastic"
		password => "p6zmi254"
		index => "milize_fp_faq"
		# document_id => "%{id}"
	}
	stdout {}
}
