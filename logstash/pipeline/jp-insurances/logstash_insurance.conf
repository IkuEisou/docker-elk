input {
	file {
		path => "/usr/share/logstash/pipeline/jp-insurances/r1_es.csv"
		start_position => "beginning"
		sincedb_path => "/dev/null"
  }
}
filter {
  csv {
    separator => ","
    columns => ["web-scraper-order","company","sub_type","title_year","summary","sample_contract","options","type"]
  }
  mutate {
    split => { "sub_type" => "/" }
    split => { "options" => "/" }
    remove_field => [ "path", "host","@timestamp","message"]
  }
  mutate {
    split => { "title_year" => '^'}
    add_field => { "title" => "%{[title_year][0]}"}
    add_field => { "year" => "%{[title_year][1]}"}
  }
  mutate {
    strip => ["title"]
    remove_field => ["path", "host","@timestamp","message","title_year"]
  }
}

## Add your filters / logstash plugins configuration here

output {
	elasticsearch {
		hosts => "elasticsearch:9200"
		user => "elastic"
		password => "p6zmi254"
		index => "insurances"
		document_id => "%{web-scraper-order}"
	}
	stdout {}
}
