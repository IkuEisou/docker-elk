input {
	file {
		path => "/usr/share/logstash/pipeline/jp-insurances/all_r1_es.csv"
		start_position => "beginning"
		sincedb_path => "/dev/null"
  }
}
filter {
  csv {
    separator => ","
    columns => ["id","web-scraper-order","company_year","type","title"]
    # "name","content","sample","options"
  }
  mutate {
    split => { "type" => "/" }
    remove_field => [ "path", "host","@timestamp","message"]
  }
  mutate {
    split => { "company_year" => ' '}
    add_field => { "company" => "%{[company_year][0]}"}
    add_field => { "year" => "%{[company_year][1]}"}
  }
  mutate {
    strip => ["title"]
    remove_field => ["path", "host","@timestamp","message","company_year"]
  }
}

## Add your filters / logstash plugins configuration here

output {
	elasticsearch {
		hosts => "elasticsearch:9200"
		user => "elastic"
		password => "changeme"
		index => "insurances"
		document_id => "%{id}"
	}
	stdout {}
}
